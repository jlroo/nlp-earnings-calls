{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59552385",
   "metadata": {},
   "source": [
    "# Data Extraction via Selenium and CIQ\n",
    "### Text Mining on Earnings Calls during a Pandemic as a Means to Predict End-Of-The-Month Stock Performances\n",
    "####  Olin School of Business <br> Jose Luis Rodriguez  <br> jlr@wustl.edu <br> Fall 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2cd814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ed12582",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c00fb",
   "metadata": {},
   "source": [
    "### HTML Page containing a list of Earning calls for the respective time period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501facc",
   "metadata": {},
   "source": [
    "### Open Page and redirect to login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2994208",
   "metadata": {},
   "outputs": [],
   "source": [
    "login = 'https://www.capitaliq.spglobal.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '/html/hotels-rest-leisure-2021.html'\n",
    "local_url = 'file:///' + os.getcwd() + html\n",
    "driver.get(local_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = driver.find_elements_by_xpath('//*/td[@data-colkey=\"name\"]')\n",
    "links = driver.find_elements_by_xpath('//*/td[@data-colkey=\"name\"]/a')\n",
    "dates = driver.find_elements_by_xpath('//*/td[@data-colkey=\"date\"]')\n",
    "trscs = driver.find_elements_by_xpath('//*/td[@data-colkey=\"transcript_type\"]')\n",
    "related = driver.find_elements_by_xpath('//*/td[@data-colkey=\"relatedEntities\"]')\n",
    "entities = {}\n",
    "for n,nm in enumerate(names):\n",
    "    d = {}\n",
    "    d['date'] = pd.to_datetime(dates[n].text).date()\n",
    "    d['time'] = pd.to_datetime(dates[n].text).time()\n",
    "    d['doc_type'] = trscs[n].text.lower().split('-')[0].strip() + '_' + trscs[n].text.lower().split('-')[1].strip()\n",
    "    d['doc_type'] = d['doc_type'].replace(' ', '_')\n",
    "    d['related'] = related[n].text.split(')')[0].replace('(','')\n",
    "    d['link'] = links[n].get_attribute('href')\n",
    "    entities[d['link']] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb5b67",
   "metadata": {},
   "source": [
    "### Single Link Workflow Word Doc Download Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(entities.keys())[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96376b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba3102",
   "metadata": {},
   "outputs": [],
   "source": [
    "buttons = driver.find_elements_by_tag_name('button')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cef2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buttons = {i.text.lower():i for i in buttons}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961fd22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME = buttons['download'].get_attribute('class').split(' ')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf825f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = driver.find_element_by_xpath('//*/div[@class=\"ag-center-cols-clipper\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b033da",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = check.find_elements_by_xpath('//*/div[@role=\"gridcell\"]')[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5bc0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.find_elements_by_tag_name('input')[1].get_attribute('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a210f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = e.find_elements_by_tag_name('input')[1]\n",
    "script = 'document.getElementById(\"' + c.get_attribute('id') + \").click()'\n",
    "driver.execute_script(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeee0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//*/div[@class=\"spg-modal-footer\"]/div/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,entry in enumerate(entities):\n",
    "    driver.get(entry['link'])\n",
    "    time.sleep(8)\n",
    "    buttons = driver.find_elements_by_tag_name('button')\n",
    "    buttons = {i.text.lower():i for i in buttons}\n",
    "    buttons['download'].click()\n",
    "    time.sleep(15)\n",
    "    cells = driver.find_element_by_xpath('//*/div[@class=\"ag-center-cols-clipper\"]')\n",
    "    cells = cells.find_elements_by_xpath('//*/div[@role=\"gridcell\"]')\n",
    "    tags = {i.text.lower().replace('\\n','_'):i for i in cells}\n",
    "    tags = tags['pdf_word'].find_elements_by_tag_name('input')\n",
    "    input_id = {i.get_attribute(\"id\").split('_')[1]:i.get_attribute(\"id\") for i in tags}\n",
    "    script = 'document.getElementById(\"' + input_id['WORD'] + '\").click()'\n",
    "    driver.execute_script(script)\n",
    "    time.sleep(2)\n",
    "    buttons = driver.find_elements_by_tag_name('button')\n",
    "    buttons = {i.text.lower():i for i in buttons}\n",
    "    buttons['download'].click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4c218",
   "metadata": {},
   "source": [
    "## HTML Extract Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for key in entities.keys():\n",
    "    driver.get(key)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        content = driver.find_element_by_class_name('json-rtf')\n",
    "    except:\n",
    "        time.sleep(20)\n",
    "        content = driver.find_element_by_class_name('json-rtf')\n",
    "    entities[key]['company'] = content.find_element_by_xpath('//*/header[@data-id=\"children.0\"]').text\n",
    "    entities[key]['speakers_info'] = {}\n",
    "    transcript = content.find_elements_by_xpath('//*/section[@data-id=\"children.2\"]')\n",
    "    speakers = content.find_elements_by_xpath('//*/section/strong')\n",
    "    participants = content.find_element_by_xpath('//*/section[@data-id=\"children.1\"]')\n",
    "    participants = participants.find_elements_by_tag_name('li')\n",
    "    entities[key]['speakers_number'] = len(participants) -1\n",
    "\n",
    "    for el in participants:\n",
    "        el = el.text.split('\\n')\n",
    "        if len(el) > 1:\n",
    "            name = el[0].upper().replace('.', '').replace(' ', '_')\n",
    "            info = el[1]\n",
    "        else:\n",
    "            if ';' in el[0]:\n",
    "                name = el[0].split(';')[0]\n",
    "                info = el[0].split(';')[1]\n",
    "            else:\n",
    "                name = el[0].upper().replace('.', '').replace(' ', '_')\n",
    "                info = name\n",
    "        entities[key]['speakers_info'][name] = info\n",
    "\n",
    "    for el in speakers:\n",
    "        spk_name = el.text.upper().replace('.', '').replace(' ', '_')\n",
    "        spk_sec = \".\".join(el.get_attribute('data-id').split('.')[:4])\n",
    "        spk_content = content.find_element_by_xpath('//*/section[@data-id=\"' + spk_sec + '\"]').text\n",
    "        if spk_name != 'OPERATOR':\n",
    "            if spk_name not in entities[key].keys(): \n",
    "                entities[key][spk_name] = spk_content.split('\\n')[1:]\n",
    "            else:\n",
    "                entities[key][spk_name].extend(spk_content.split('\\n')[1:])\n",
    "    data.append(entities[key])\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9c403",
   "metadata": {},
   "source": [
    "## Transcripts Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd386ca",
   "metadata": {},
   "source": [
    "### Retail Restaurant and Leisure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8aed8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.capitaliq.spglobal.com/web/client?auth=inherit#')\n",
    "time.sleep(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a7077a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {i.get_attribute('name'):i for i in driver.find_elements(by = By.TAG_NAME, value='input') \n",
    " if i.get_attribute('name') != ''}\n",
    "sq = 'return document.getElementsByClassName(\"login-content\")[5].getElementsByTagName(\"button\")'\n",
    "button = driver.execute_script(sq)\n",
    "user = inputs['username']\n",
    "pwd = inputs['password']\n",
    "\n",
    "user.send_keys('jrodriguez@midwestbankcentre.com')\n",
    "pwd.send_keys('J@n@3!F3b')\n",
    "\n",
    "button[0].click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f276d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '/html/hotels-rest-leisure-2020.html'\n",
    "local_url = 'file:///' + os.getcwd() + html\n",
    "driver.get(local_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf441ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = driver.find_elements_by_xpath('//*/td[@data-colkey=\"name\"]')\n",
    "links = driver.find_elements_by_xpath('//*/td[@data-colkey=\"name\"]/a')\n",
    "dates = driver.find_elements_by_xpath('//*/td[@data-colkey=\"date\"]')\n",
    "trscs = driver.find_elements_by_xpath('//*/td[@data-colkey=\"transcript_type\"]')\n",
    "related = driver.find_elements_by_xpath('//*/td[@data-colkey=\"relatedEntities\"]')\n",
    "entities = {}\n",
    "for n,nm in enumerate(names):\n",
    "    d = {}\n",
    "    d['date'] = pd.to_datetime(dates[n].text).date()\n",
    "    d['time'] = pd.to_datetime(dates[n].text).time()\n",
    "    d['doc_type'] = trscs[n].text.lower().split('-')[0].strip() + '_' + trscs[n].text.lower().split('-')[1].strip()\n",
    "    d['doc_type'] = d['doc_type'].replace(' ', '_')\n",
    "    d['related'] = related[n].text.split(')')[0].replace('(','')\n",
    "    d['link'] = links[n].get_attribute('href')\n",
    "    entities[d['link']] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bf6607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = []\n",
    "\n",
    "for key in entities.keys():\n",
    "    if key in keys:\n",
    "        continue\n",
    "    driver.get(key)\n",
    "    time.sleep(7)\n",
    "    header = driver.find_element(by = By.TAG_NAME, value='main')\n",
    "    header = header.find_element(by = By.TAG_NAME, value='header')\n",
    "    pdf = header.get_attribute('data-display-format')\n",
    "    if pdf == 'pdf':\n",
    "        continue\n",
    "    try:\n",
    "        content = driver.find_element_by_class_name('json-rtf')\n",
    "    except:\n",
    "        try:\n",
    "            time.sleep(15)\n",
    "            content = driver.find_element_by_class_name('json-rtf')      \n",
    "        except:\n",
    "            main = driver.find_element(by=By.TAG_NAME, value='main')\n",
    "            src_html = main.get_attribute('outerHTML')\n",
    "            name = entities[key]['related'].replace(':','_')\n",
    "            with open('html/' + name,'w') as f:\n",
    "                f.write(src_html)\n",
    "            continue\n",
    "    \n",
    "    entities[key]['company'] = content.find_element_by_xpath('//*/header[@data-id=\"children.0\"]').text\n",
    "    entities[key]['speakers_info'] = {}\n",
    "    entities[key]['speakers_transcript'] = {}\n",
    "    transcript = content.find_elements_by_xpath('//*/section[@data-id=\"children.2\"]')\n",
    "    speakers = content.find_elements_by_xpath('//*/section/strong')\n",
    "    participants = content.find_element_by_xpath('//*/section[@data-id=\"children.1\"]')\n",
    "    participants = participants.find_elements_by_tag_name('li')\n",
    "    entities[key]['speakers_number'] = len(participants) -1\n",
    "\n",
    "    for el in participants:\n",
    "        el = el.text.split('\\n')\n",
    "        if len(el) > 1:\n",
    "            name = el[0].upper().replace('.', '').replace(' ', '_')\n",
    "            info = el[1]\n",
    "        else:\n",
    "            if ';' in el[0]:\n",
    "                name = el[0].split(';')[0]\n",
    "                info = el[0].split(';')[1]\n",
    "            else:\n",
    "                name = el[0].upper().replace('.', '').replace(' ', '_')\n",
    "                info = name\n",
    "        entities[key]['speakers_info'][name] = info\n",
    "\n",
    "    corpus = \"\"\n",
    "    for el in speakers:\n",
    "        spk_name = el.text.upper().replace('.', '').replace(' ', '_')\n",
    "        spk_sec = \".\".join(el.get_attribute('data-id').split('.')[:4])\n",
    "        spk_content = content.find_element_by_xpath('//*/section[@data-id=\"' + spk_sec + '\"]').text\n",
    "        if spk_name != 'OPERATOR':\n",
    "            if spk_name not in entities[key]['speakers_transcript'].keys(): \n",
    "                entities[key]['speakers_transcript'][spk_name] = spk_content.split('\\n')[1:]\n",
    "                corpus += \"\\n\".join(spk_content.split('\\n')[1:])\n",
    "            else:\n",
    "                entities[key]['speakers_transcript'][spk_name].extend(spk_content.split('\\n')[1:])\n",
    "                corpus += \"\\n\".join(spk_content.split('\\n')[1:])\n",
    "    entities[key]['corpus'] = corpus\n",
    "    data.append(entities[key])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14f27277",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrl = []\n",
    "for entity in data:    \n",
    "    corpus = \" \"\n",
    "    for key in entity['speakers_transcript'].keys():\n",
    "        corpus += \"\\n\".join(entity['speakers_transcript'][key])\n",
    "    entity['corpus'] = corpus\n",
    "    hrl.append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8944443f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrl_df = pd.DataFrame.from_dict(hrl)\n",
    "hrl_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4228fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrl_df.to_csv('data/hrl_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc81c33",
   "metadata": {},
   "source": [
    "### Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90db6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = os.getcwd()\n",
    "html = '/html/transportation-2021.html'\n",
    "local_url = 'file:///' + src_path + html\n",
    "driver.get(local_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b10ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = driver.find_elements_by_xpath('//*/td[@data-colkey=\"name\"]')\n",
    "links = driver.find_elements_by_xpath('//*/td[@data-colkey=\"name\"]/a')\n",
    "dates = driver.find_elements_by_xpath('//*/td[@data-colkey=\"date\"]')\n",
    "trscs = driver.find_elements_by_xpath('//*/td[@data-colkey=\"transcript_type\"]')\n",
    "related = driver.find_elements_by_xpath('//*/td[@data-colkey=\"relatedEntities\"]')\n",
    "entities = {}\n",
    "for n,nm in enumerate(names):\n",
    "    d = {}\n",
    "    d['date'] = pd.to_datetime(dates[n].text).date()\n",
    "    d['time'] = pd.to_datetime(dates[n].text).time()\n",
    "    d['doc_type'] = trscs[n].text.lower().split('-')[0].strip() + '_' + trscs[n].text.lower().split('-')[1].strip()\n",
    "    d['doc_type'] = d['doc_type'].replace(' ', '_')\n",
    "    d['related'] = related[n].text.split(')')[0].replace('(','')\n",
    "    d['link'] = links[n].get_attribute('href')\n",
    "    entities[d['link']] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81f25674",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set([i['link'] for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b5afa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for key in entities.keys():\n",
    "    driver.get(key)\n",
    "    time.sleep(8)\n",
    "    try:\n",
    "        header = driver.find_element(by = By.TAG_NAME, value='main')\n",
    "        header = header.find_element(by = By.TAG_NAME, value='header')\n",
    "        pdf = header.get_attribute('data-display-format')\n",
    "        if pdf == 'pdf':\n",
    "            continue\n",
    "        content = driver.find_element_by_class_name('json-rtf')\n",
    "    except:\n",
    "        try:\n",
    "            time.sleep(15)\n",
    "            content = driver.find_element_by_class_name('json-rtf')      \n",
    "        except:\n",
    "            main = driver.find_element(by=By.TAG_NAME, value='main')\n",
    "            src_html = main.get_attribute('outerHTML')\n",
    "            name = entities[key]['related'].replace(':','_')\n",
    "            with open('html/' + name,'w') as f:\n",
    "                f.write(src_html)\n",
    "            continue\n",
    "    \n",
    "    entities[key]['company'] = content.find_element_by_xpath('//*/header[@data-id=\"children.0\"]').text\n",
    "    entities[key]['speakers_info'] = {}\n",
    "    entities[key]['speakers_transcript'] = {}\n",
    "    transcript = content.find_elements_by_xpath('//*/section[@data-id=\"children.2\"]')\n",
    "    speakers = content.find_elements_by_xpath('//*/section/strong')\n",
    "    participants = content.find_element_by_xpath('//*/section[@data-id=\"children.1\"]')\n",
    "    participants = participants.find_elements_by_tag_name('li')\n",
    "    entities[key]['speakers_number'] = len(participants) -1\n",
    "\n",
    "    for el in participants:\n",
    "        el = el.text.split('\\n')\n",
    "        if len(el) > 1:\n",
    "            name = el[0].upper().replace('.', '').replace(' ', '_')\n",
    "            info = el[1]\n",
    "        else:\n",
    "            if ';' in el[0]:\n",
    "                name = el[0].split(';')[0]\n",
    "                info = el[0].split(';')[1]\n",
    "            else:\n",
    "                name = el[0].upper().replace('.', '').replace(' ', '_')\n",
    "                info = name\n",
    "        entities[key]['speakers_info'][name] = info\n",
    "\n",
    "    corpus = \"\"\n",
    "    for el in speakers:\n",
    "        spk_name = el.text.upper().replace('.', '').replace(' ', '_')\n",
    "        spk_sec = \".\".join(el.get_attribute('data-id').split('.')[:4])\n",
    "        spk_content = content.find_element_by_xpath('//*/section[@data-id=\"' + spk_sec + '\"]').text\n",
    "        if spk_name != 'OPERATOR':\n",
    "            if spk_name not in entities[key]['speakers_transcript'].keys(): \n",
    "                entities[key]['speakers_transcript'][spk_name] = spk_content.split('\\n')[1:]\n",
    "                corpus += \"\\n\".join(spk_content.split('\\n')[1:])\n",
    "            else:\n",
    "                entities[key]['speakers_transcript'][spk_name].extend(spk_content.split('\\n')[1:])\n",
    "                corpus += \"\\n\".join(spk_content.split('\\n')[1:])\n",
    "    entities[key]['corpus'] = corpus\n",
    "    data.append(entities[key])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0623b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d33a055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trs_df = pd.DataFrame.from_dict(data)\n",
    "trs_df.to_csv('data/trs_2021.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52ea55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
